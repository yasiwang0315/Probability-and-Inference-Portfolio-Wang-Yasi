---
title: "09-method-comparison"
author: Yasi Wang
date: 11/27/2019
output: 
  html_notebook: 
    highlight: tango
    theme: cosmo
---

Last time, we've discussed about confidence interval (CI) and coverage probability. This time, we will do more simulations with different estimations and calculate their corresponding coverage probabilities.

# Introduction
***

## Method of Moment estimation
**Method of moment** is a method of estimation of population parameters. It usually contains five steps:

1. Express the population moments as functions of the parameters of interest.
    + Choose a parametric distribution
    + Identify the distribution parameters.

2. Calculate sample moments.
3. Create system of equations equating distribution moments to sample moments.
4. Solve system of equations for distribution parameters.
5. $\hat{F}_X = F_X(x | \theta = \hat{\theta})$

## Kernal Density estimation
**Kernel density estimation** (KDE) is a non-parametric way to estimate the probability density function of a random variable. It is a fundamental data smoothing problem where inferences about the population are made, based on a finite data sample. We usually use `gaussian` kernal function.


## Bootstrap estimation
The general idea of **bootstrap** is to create new samples of size N by sampling rows with replacement. When we only have single sample, we can use bootrstrap to simulate from the sample. This technique allows estimation of the sampling distribution of almost any statistic using random sampling methods. Generally, it belongs to resampling methods.

<center>
![](bootstrap.svg){ width=60% } 
</center>

Usually, we use `array(sample(data, N * R, replace = TRUE), dim = c(N, R))` to generate data from bootstrap measure.

```{r include=FALSE}
library(tidyverse)
```


# Simulation
***
**Step 1: Generate data: create the function that can generate data with normal distribution or gamma distribution.**

For convenience, I added for to each value if it is normal distribution. Thus all the values can be positive.

```{r}
generate_data <- function(N, dist, sh, sc) {
  if(dist == "norm") {
    return(rnorm(N) + 4)
  } else if(dist == "gamma") {
    return(rgamma(N, shape = sh, scale = sc))
  }
}
```

**Step 2: Estimate confidence interval: create the function that can return the 95% confidence interval from the approximated sampling distribution.**

There are four estimation methods: Method of moment on normal distribution, Method of moment on gamma distribution, kernal density distribution estimate, bootstrap estimate. I combined them together and calculated the corresponding CI.

```{r}
estimate.ci <- function(data, mod, R = 5000, par.int, smoo = 0.3) {
  N <- length(data)
  sum.measure <- get(par.int)

  if (mod=="MMnorm"){ 
    mm.mean <- mean(data)
    mm.sd <- sd(data)
    sim.data <- rnorm(length(data),mm.mean,mm.sd)
    
    sim.data <- array(rnorm(N*R,mm.mean,mm.sd),dim=c(N,R))
    samp.dist <- apply(sim.data,2,sum.measure)

  } else if(mod == "MMgamma") {
    mm.shape <- mean(data)^2/var(data)
    mm.scale <- var(data)/mean(data)
    
    sim.data <- array(rgamma(length(data)*R, shape = mm.shape, scale = mm.scale), dim = c(N, R))
    samp.dist <- apply(sim.data, 2, FUN = sum.measure)
    
  } else if(mod == "KDE") { 
    ecdfstar <- function(t, data, smooth = smoo) {
      outer(t, data, function(a, b) {pnorm(a, b, smooth)}) %>% rowMeans
      }
    
    tbl <- data.frame(
      x = seq(min(data) - 2*sd(data), max(data) + 2*sd(data), by = 0.01)
    )
    tbl$p <- ecdfstar(tbl$x, data, smoo)
    tbl <- tbl[!duplicated(tbl$p),]
    
    qkde <- function(ps, tbl){
      rows <- cut(ps, tbl$p, labels = FALSE)
      tbl[rows, "x"]
      }
    
    U <- runif(N * R)
    sim.data <- array(qkde(U, tbl), dim = c(N, R))
    samp.dist <- apply(sim.data, 2, FUN = sum.measure)

  } else if(mod == "Boot") {
    sim.data <- array(sample(data, N * R, replace = TRUE), dim = c(N, R))
    samp.dist <- apply(sim.data, 2, FUN = sum.measure)
    
  }
  return(quantile(samp.dist, c(0.05, 0.95)))
}

```


**Step 3: Capture the parameters of interest.**

After calculating the CI, I created the function to estimate whether the parameter (min or median) is captured by that range.

```{r}
capture_par <- function(ci, true.par) {
  1 * (ci[1] < true.par & true.par < ci[2])
}

```


**Step 4: All together.**
With N = 201, we put all the things together to calculate the coverage probabilities in each condition.

```{r}
N <- 201
shape.set <- 1.4
scale.set <- 3

true.norm.med <- qnorm(0.5)
true.norm.min <- mean(apply(array(rnorm(N*10000), dim = c(N, 10000)), 2, min))

true.gamma.med <- qgamma(0.5, shape = shape.set, scale = scale.set) 
true.gamma.min <- mean(apply(array(rgamma(N*10000, shape = shape.set, scale = scale.set), dim = c(N, 10000)), 2, min))
  
simsettings <- expand.grid(dist = c("norm", "gamma"), model = c("MMnorm", "MMgamma", "KDE", "Boot"), par.int = c("median", "min"), cov.prob =NA, stringsAsFactors = FALSE, KEEP.OUT.ATTRS = FALSE)


for (k in 1:nrow(simsettings)){
  dist1 <- simsettings[k, 1]
  model1 <- simsettings[k, 2]
  par.int1 <- simsettings[k, 3]
  
  if (dist1 == "norm" & par.int1 == "median") {
    true.par1 = true.norm.med + 4
  } else if (dist1 == "gamma" & par.int1 == "median") {
    true.par1 = true.gamma.med
  } else if (dist1 == "norm" & par.int1 == "min") {
    true.par1 = true.norm.min + 4
  } else if (dist1 == "gamma" & par.int1 == "min") {
    true.par1 = true.gamma.min
  }
  cover <- NA
  
  for (sims in 1:1000) {
    cover[sims] <- generate_data(N, dist1, sh = shape.set, sc = scale.set) %>% estimate.ci(mod = model1, par.int = par.int1, R = 5000) %>% capture_par(true.par = true.par1)
    simsettings[k ,4] <- mean(cover)

  }
}
```


```{r}
simsettings
```


# Conclusion
***
Among all the estimation methods, we can find that:

- method of moments is the best method (except for MMnorm on gamma distribution or MMgamma on normal distribution) that can capture more than 94% of the parameters of interest. Also, it estimates more accurate when true distribution is standard normal distribution. 
- bootstrap methods estimates better on capturing median than min. 
- kernal density estimation could have almost 90% accuracy when the parameter is median. When capturing min, this method would fail when the true distribution is gamma distribution.
- On the whole, capturing median is much easier than min in either distribution. This is probability because median is more robust to outliers. Therefore, the coverage probability will be high enough in whatever estimation methods.

Coverage probability will be affected by many factors. For example, the estimation methods, the parameters of interest, the population distributions, etc. Only knowing which is the best estimation method in different conditions, can we get the most accurate result in the simulation process.

