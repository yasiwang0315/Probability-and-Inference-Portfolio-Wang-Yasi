---
title: "06-order-statistic"
date: "9/29/2019"
author: "Yasi Wang"
output: 
  html_notebook: 
    highlight: tango
    theme: cerulean
---  
The median is an important quantity in data analysis. It represents the middle value of the data distribution. Estimates of the median, however, have a degree of uncertainty because (a) the estimates are calculated from a finite sample and (b) the data distribution of the underlying data is generally unknown. One important roles of a data scientist is to quantify and to communicate the degree of uncertainty in his or her data analysis.

Today, I'll demonstrate the empirical and theoretical methods to show the order statistics' properties.

## Density for the median

Begin with the median from a sample of N=200 from the standard normal distribution. The density function for the median in this sample is listed below. 

**Note:** the 100th order statistic is approximately the median.
```{r}
dorder <- function(x){
  100*
  choose(200,100)*
  (pnorm(x,0,1))^(100-1)*
  (1-pnorm(x,0,1))^(200-100)*
  dnorm(x,0,1)  
}

curve(
  dorder(x)
  , xlim = c(-0.5, 0.5)
  , xlab = parse(text = "X[100]")
  , ylab = "Density"
  , lwd = 3
  , col = "orange"
  , main = "Density for the Median"
)

```
```{r eval=FALSE, include=FALSE}
# density is not the probability, it is the relative likelihood
```

We can find that this graph is symmetric, with the symmetry axis of X<sub>100</sub> = 0. Also, when X<sub>100</sub> = 0, the density has the largest value. Away from 0, the density becomes smaller.

## Probability for the median

The the probability function for the median in this sample and the corresponding function curve are demonstrated below. 
```{r}
porder <- function(x){
  pbinom(100-1, 200, pnorm(x), lower.tail = FALSE)
}

curve(
  porder(x)
  , xlim = c(-0.5, 0.5)
  , xlab = parse(text = "X[100]")
  , ylab = "Probability"
  , lwd = 3
  , col = "orange"
  , main = "Probability for the Median"
)

```

As the X<sub>100</sub> increases, the probability increases and gets stable at 1 when X<sub>100</sub> equals to 0.4.

## Quantile for the median

The quantile function for the median in this sample is written below. 

```{r}
qorder <- function(p) {
  out <- p
  for (i in seq_along(p)) {
    pnew <- function(x) {
      pbinom(100-1, 200, pnorm(x), lower.tail = FALSE) - p[i]
    }
    out[i] <- uniroot(pnew, c(-10,10))$root
  }
  out
}

p <- seq(1/5000, 4999/5000, 1/5000)
plot(p, qorder(p)
  , xlim = c(0, 1)
  , xlab = parse(text = "Quantile")
  , ylab = parse(text = "X[100]")
  , type = "l"
  , lwd = 3
  , main = "Quantile for the Median"
  , col = "orange"
)
# 
# curve(qorder(x)
#   , xlab = parse(text = "Quantile")
#   , ylab = "Probability"
#   , type = "l"
#   , lwd = 3
#   , main = "Quantile for the Median"
#   , col = "orange"
# )
```
We can notice that for the quantile for the median, as the quantile increases, the X<sub>100</sub> increases from -0.3 to 0.3.


## CDF and ECDF

I simulated the sampling distribution for the median, and created a plot of the empirical CDF (ECDF). 

```{r}
set.seed(123)

sim_median <- c()
for (i in 1:5000) {
  sim_median[i] <- median(rnorm(200))
}

sim_median_ecdf <- ecdf(sim_median) 
plot(sim_median_ecdf, do.points = FALSE, col = "red", lwd = 3, main = "ECDF and CDF", xlab = "Medians")
curve(porder(x), add = TRUE, lwd = 3, col = "blue")
legend(
    "topleft"
  , c("ECDF","CDF")
  , lwd = 3
  , col = c("red","blue")
  , bty = "n"
)

```
The CDF and ECDF are almost perfectly overlapped.


## Histogram and density

Using the simulated sampling distribution from the previous question, I created a histogram and overlayed the histogram with a plot of the density function.

```{r}
hist(sim_median, breaks = 100, col = "lightgray", freq = FALSE,
     xlab = parse(text = "X[100]"), ylab = "Density", main = "Sampling distribution")
curve(
    dorder(x)
  , add = TRUE
  , xlab = parse(text="X[(100)]")
  , ylab = "Density"
  , col = "blue"
  , lwd = 3
)
```

The sampling distribution (histogram) matches with the population distribution (density plot) perfectly.

## QQ plot

One very common way to compare a random sample to a theoretical candidate distribution is the QQ plot. It is created by ploting quantiles of the theoretical distribution on the x-axis and empirical quantiles from the sample on the y-axis.

```{r include=FALSE}
# library(devtools)
# install_github("thomasgstewart/tgsify")
library(tgsify)
```

### Median order statistic distribution 

I generated a QQ plot for the simulated data of the median relative to the known sampling distribution of the median.
```{r}
p1 <- ppoints(200)
x1 <- qorder(p)
y1 <- quantile(sim_median, probs = p)

plotstyle(style = upright)
plot(x1,y1, asp = 1, xlab = "Theoretical quantile", ylab = "Sample quantile")
abline(0,1)
```

Clearly, the plotted points fall along the line y=x. Thus, we can say that the simulated data agree with the theoretical sampling distribution.

### Functions with K<sub>th</sub> order statistic

In this step, I Modified the dorder, porder, and qorder functions so that the functions take a new parameter k (for the k<sub>th</sub> order statistic) so that the functions will work for any order statistic and not just the median.

```{r}
dorder_new <- function(k, x){
  k*
  choose(200,k)*
  (pnorm(x))^(k-1)*
  (1-pnorm(x))^(200-k)*
  dnorm(x)  
}

porder_new <- function(k, x){
  pbinom(k-1, 200, pnorm(x), lower.tail = FALSE)
}

qorder_new <- function(k, p) {
  out <- p
  for (i in seq_along(p)) {
    pnew <- function(x) {
      pbinom(k-1, 200, pnorm(x), lower.tail = FALSE) - p[i]
    }
    out[i] <- uniroot(pnew, c(-10,10))$root
  }
  out
}
```


### Largest order statistic distribution

Then I generated the QQ plot for simulated data from the sampling distribution of the sample max and the theoretical largest order statistic distribution.

```{r}
set.seed(123)

sim_max <- c()
for (i in 1:5000) {
  sim_max[i] <- max(rnorm(200))
}

p2 <- ppoints(200)
x2 <- qorder_new(k = 200, p)
y2 <- quantile(sim_max, probs = p)

plotstyle(style = upright)
plot(x2,y2, asp = 1, xlab = "Theoretical quantile", ylab = "Sample quantile")
abline(0,1)
```

The plotted points fall along the line y=x, which means that the simulated data agree with the theoretical sampling distribution.


## Functions all together

I Modified the dorder, porder, and qorder functions so that the functions take new parameters dist and ... so that the functions will work for any continuous distribution that has d and p functions defined in R.

```{r include=FALSE}
require(dplyr)
require(data.table)
`%|%` <- function(a,b) paste0(a,b)
require(tgsify) #can be installed with devtools::install_github("thomasgstewart/tgsify")
```



```{r}
dist = c("norm", "exp", "binom", "unif", "beta")

dorder_any <- function(dist, k, x, n, ...){
  pf <- get("p" %|% dist)
  df <- get("d" %|% dist)
  
  k*
  choose(n,k)*
  (pf(x,...))^(k-1)*
  (1-pf(x, ...))^(n-k)*
  df(x, ...)  
}


porder_any <- function(dist, k, x, n, ...){
  pf <- get("p" %|% dist)
  pbinom(k-1, n, pf(x, ...), lower.tail = FALSE)
}


qorder_any <- function(k, x, n) {
  pf <- get("p" %|% dist)
  out <- x
  for (i in seq_along(x)) {
    pnew <- function(x) {
      pbinom(k-1, n, pf(x, ...), lower.tail = FALSE) - p[i]
    }
    out[i] <- uniroot(pnew, c(-100,100))$root
  }
  out
}
```

### Probability and Density

I Use the newly modified functions to plot the probability and density functions for the sample min (N=200).

```{r}
curve(
  dorder_any(dist = "norm", k = 1, x, n = 200)
  , xlim = c(-5, 1)
  , xlab = parse(text = "X[1]")
  , ylab = "Density"
  , lwd = 3
  , col = "red"
  , main = "Normal distribution: Density for the Minimum"
)
curve(
  porder_any("norm", 1, x, 200)
  , xlim = c(-5, 0)
  , xlab = parse(text = "X[1]")
  , ylab = "Probability"
  , lwd = 3
  , col = "red"
  , main = "Normal distribution: Probability for the Minimum"
)


curve(
  dorder_any(dist = "exp", 1, x, 200, rate = 2)
  , xlim = c(0, 0.03)
  , xlab = parse(text = "X[1]")
  , ylab = "Density"
  , lwd = 3
  , col = "blue"
  , main = "Exponential distribution: Density for the Minimum"
)

curve(
  porder_any(dist = "exp", 1, x, 200, rate = 2)
  , xlim = c(0, 0.03)
  , xlab = parse(text = "X[1]")
  , ylab = "Density"
  , lwd = 3
  , col = "blue"
  , main = "Exponential distribution: Probability for the Minimum"
)
```

As for normal distribution, I plotted the probability and density functions for the 1<sub>st</sub> ordered value. We can see that the density function is not symmetric, but still goes increase and then decrease. As for probability, it increases and gets stable at 1 when X<sub>1</sub> equals to -2.

As for exponential distribution, as X<sub>1</sub> increases from 0, the density decreases all the time, while the probability increases.

Thus, we can conclude that:

- Different distributions have different density functions and probability functions.
- Different positions in the order statistics have different density functions and probability functions.
