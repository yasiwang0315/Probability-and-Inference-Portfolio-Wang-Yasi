---
title: "06-order-statistic"
date: "9/29/2019"
author: "Yasi Wang"
output: 
  html_notebook: 
    highlight: tango
    theme: cerulean
---  
I haven't finished yet. I'll finish by Tuesday.

The median is an important quantity in data analysis. It represents the middle value of the data distribution. Estimates of the median, however, have a degree of uncertainty because (a) the estimates are calculated from a finite sample and (b) the data distribution of the underlying data is generally unknown. One important roles of a data scientist is to quantify and to communicate the degree of uncertainty in his or her data analysis.

Today, I'll demonstrate the empirical and theoretical methods to show the order statistics' properties.

## Density for the median

Begin with the median from a sample of N=200 from the standard normal distribution. The density function for the median in this sample is listed below. 

**Note:** the 100th order statistic is approximately the median.
```{r}
dorder <- function(x){
  100*
  choose(200,100)*
  (pnorm(x,0,1))^(100-1)*
  (1-pnorm(x,0,1))^(200-100)*
  dnorm(x,0,1)  
}

curve(
  dorder(x)
  , xlim = c(-0.5, 0.5)
  , xlab = parse(text = "X[100]")
  , ylab = "Density"
  , lwd = 3
  , col = "orange"
  , main = "Density for the Median"
)

```
From the graph, we can find that  if the median increase from negative infinite to 0, the density for this median will increase from 0 to 4. the probability 
We can find that this graph is symmetric, with the symmetry axis of X<sub>100</sub> = 0. Also, when X<sub>100</sub> = 0, the density has the largest value. Away from 0, the density becomes smaller.



## Probability for the median

The the probability function for the median in this sample and the corresponding function curve are demonstrated below. 
```{r}
porder <- function(x){
  pbinom(100-1, 200, pnorm(x), lower.tail = FALSE)
}

curve(
  porder(x)
  , xlim = c(-0.5, 0.5)
  , xlab = parse(text = "X[100]")
  , ylab = "Probability"
  , lwd = 3
  , col = "orange"
  , main = "Probability for the Median"
)

```


## Quantile for the median

The quantile function for the median in this sample is written below. 

```{r}
qorder <- function(p) {
  out <- p
  for (i in seq_along(p)) {
    pnew <- function(x) {
      pbinom(100-1, 200, pnorm(x), lower.tail = FALSE) - p[i]
    }
    out[i] <- uniroot(pnew, c(-10,10))$root
  }
  out
}

p <- seq(1/5000, 4999/5000, 1/5000)
plot(p, qorder(p)
  , xlim = c(0, 1)
  , xlab = parse(text = "Quantile")
  , ylab = parse(text = "X[100]")
  , type = "l"
  , lwd = 3
  , main = "Quantile for the Median"
  , col = "orange"
)
# 
# curve(qorder(x)
#   , xlab = parse(text = "Quantile")
#   , ylab = "Probability"
#   , type = "l"
#   , lwd = 3
#   , main = "Quantile for the Median"
#   , col = "orange"
# )
```
We can notice that for the quantile for the median, as the quantile increases, the probability of increases.


Q: Simulate the sampling distribution for the median as you did in the previous deliverable. Create a plot of the empirical CDF (ECDF). Overlay the plot of the ECDF with a plot of the CDF.

```{r}
set.seed(123)

sim_median <- c()
for (i in 1:5000) {
  sim_median[i] <- median(rnorm(200))
}

sim_median_ecdf <- ecdf(sim_median) 
plot(sim_median_ecdf, do.points = FALSE, col = "red", lwd = 3, main = "ECDF and CDF")
curve(porder(x), add = TRUE, lwd = 3, col = "blue")
legend(
    "topleft"
  , c("ECDF","CDF")
  , lwd = 3
  , col = c("red","blue")
  , bty = "n"
)

```
The CDF and ECDF are perfectly overlapped.


## Histogram and density

Using the simulated sampling distribution from the previous question, I created a histogram and overlay the histogram with a plot of the density function.

```{r}
hist(sim_median, breaks = 30, col = "lightgray", freq = FALSE,
     xlab = parse(text = "X[100]"), ylab = "Density", main = "Sampling distribution")
lines(density(sim_median), col = "orange", lwd = 3)
```


## QQ plot

One very common way to compare a random sample to a theoretical candidate distribution is the QQ plot. It is created by ploting quantiles of the theoretical distribution on the x-axis and empirical quantiles from the sample on the y-axis.

```{r include=FALSE}
# library(devtools)
# install_github("thomasgstewart/tgsify")
library(tgsify)
```

### Median order statistic distribution 

I generated a QQ plot for the simulated data of the median relative to the known sampling distribution of the median.
```{r}
x1 <- qorder((1:199)/200)
y1 <- quantile(sim_median, probs = (1:199)/200)

plotstyle(style = upright)
plot(x1,y1, asp = 1, xlab = "Theoretical quantile", ylab = "Sample quantile")
abline(0,1)
```

Clearly, the plotted points fall along the line y=x. Thus, we can say that the simulated data agree with the theoretical sampling distribution.

### Functions with K<sub>th</sub> order statistic

In this step, I Modified the dorder, porder, and qorder functions so that the functions take a new parameter k (for the k<sub>th</sub> order statistic) so that the functions will work for any order statistic and not just the median.

```{r}
dorder_new <- function(k, x){
  k*
  choose(200,k)*
  (pnorm(x))^(k-1)*
  (1-pnorm(x))^(200-k)*
  dnorm(x)  
}

porder_new <- function(k, x){
  pbinom(k-1, 200, pnorm(x), lower.tail = FALSE)
}

qorder_new <- function(k, p) {
  out <- p
  for (i in seq_along(p)) {
    pnew <- function(x) {
      pbinom(k-1, 200, pnorm(x), lower.tail = FALSE) - p[i]
    }
    out[i] <- uniroot(pnew, c(-10,10))$root
  }
  out
}
```


### Largest order statistic distribution

Then I generated the QQ plot for simulated data from the sampling distribution of the sample max and the theoretical largest order statistic distribution.

```{r}
set.seed(123)

sim_max <- c()
for (i in 1:5000) {
  sim_max[i] <- max(rnorm(200))
}

x2 <- qorder_new(k = 200, (1:199)/200)
y2 <- quantile(sim_max, probs = (1:199)/200)

plotstyle(style = upright)
plot(x2,y2, asp = 1, xlab = "Theoretical quantile", ylab = "Sample quantile")
abline(0,1)
```

## Functions with all together

I Modified the dorder, porder, and qorder functions so that the functions take new parameters dist and ... so that the functions will work for any continuous distribution that has d and p functions defined in R.
```{r}
require(dplyr)
require(data.table)
`%|%` <- function(a,b) paste0(a,b)
require(tgsify) #can be installed with devtools::install_github("thomasgstewart/tgsify")


dist = c("norm", "exp", "binom", "unif", "beta")

dorder_any <- function(dist, k, x, n){
  pf <- get("p" %|% dist)
  df <- get("d" %|% dist)
  
  k*
  choose(n,k)*
  (pf(x))^(k-1)*
  (1-pf(x))^(n-k)*
  df(x)  
}

porder_any <- function(dist, k, x, n){
  pf <- get("p" %|% dist)
  pbinom(k-1, n, pf(x), lower.tail = FALSE)
}

qorder_any <- function(k, x, n) {
  pf <- get("p" %|% dist)

  out <- x
  for (i in seq_along(x)) {
    pnew <- function(x) {
      pbinom(k-1, n, pf(x), lower.tail = FALSE) - p[i]
    }
    out[i] <- uniroot(pnew, c(-100,100))$root
  }
  out
}
```

### Probability and Density

I Use the newly modified functions to plot the probability and density functions for the sample min (N=200).

```{r}
dist = c("norm", "exp", "binom", "unif", "beta")
curve(
  dorder_any("norm", 1, x, 200)
  , xlim = c(-1.5, 1)
  , xlab = parse(text = "X[100]")
  , ylab = "Density"
  , lwd = 3
  , col = "orange"
  , main = "Density for the Minimum"
)

curve(
  dorder_any("exp", 1, x, 200)
  , xlim = c(0, 0.1)
  , xlab = parse(text = "X[100]")
  , ylab = "Density"
  , lwd = 3
  , col = "blue"
  , main = "Density for the Minimum"
)


curve(
  porder_any("norm", 1, x, 200)
  , xlim = c(-1.5, -1)
  , xlab = parse(text = "X[100]")
  , ylab = "Probability"
  , lwd = 3
  , col = "red"
  , main = "Probability for the Minimum"
)

```

